{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec890593-49e0-4645-93f2-65a5ddfa9443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "\n",
    "from torch_geometric.nn.models import GCN\n",
    "from models.DGI import DeepGraphInfomax\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import to_undirected, to_networkx\n",
    "#from OpenGraphCon import OpenGraph\n",
    "from open_dataset import load_dataset,load_amazon_datasets, load_plentoid, load_folds, create_class_folds, load_folds_class_variation\n",
    "from torch_geometric.utils import one_hot, spmm\n",
    "from torch_geometric.datasets import Planetoid, Amazon, Reddit2\n",
    "from functools import partial\n",
    "from open_dataset import load_reddit2,load_folds\n",
    "from torch_geometric.utils import homophily\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import page_rank\n",
    "import matplotlib.pyplot as plt\n",
    "from models.OpenGCN import OpenGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b32655-c03e-4163-8f4e-1805dc02f4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([0.1, 0.1, 0.1, 0.1])\n",
    "y = x/x.norm()\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03fabc27-4d8a-41da-8ed7-9b26f4ffd857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([1, 2, 3, 7])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "-----------\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([3, 5, 6, 7])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "-----------\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([0, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "-----------\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([0, 1, 2, 4])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "datasets = load_folds(\"photo\", unknown_class_ratio=0.2)\n",
    "for data in datasets:\n",
    "    print(\"-----------\")\n",
    "    print(data.y.unique())\n",
    "    print(data.y[data.labeled_mask].unique())\n",
    "    print(data.y[data.unlabeled_mask].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f343d720-7e10-4d96-8d14-53c46a38ef0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([169343, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(*('cuda', 1) if torch.cuda.is_available() else 'cpu')\n",
    "datasets = load_folds(\"ogb-arxiv\", unknown_class_ratio=0.2, fixed=False)\n",
    "data = datasets[0]\n",
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8fb66d-d3c8-440d-be34-eca56670e6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007c01a4-0955-4251-9c5b-e2bcfff01903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[data.all_class_val_mask].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fd1889c-f12e-417f-b4d4-20e6f3729328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([69689])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[data.labeled_mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c32a70b8-757a-43b7-bae9-232d23f9dc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90941)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31fd89df-20c1-4556-9c53-ab1218267a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"test.pt\")\n",
    "torch.save(data, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5532cdd8-a03a-4fc8-908c-2b7fb6eee36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=169343, edge_index=[2, 2315598], x=[169343, 128], node_year=[169343], y=[169343], train_mask=[169343], val_mask=[169343], test_mask=[169343], page_rank=[169343], classes=[40], known_classes=[24], val_classes=[8], test_classes=[8], unknown_classes=[16], known_class_mask=[169343], labeled_mask=[169343], val_class_mask=[169343], known_class_val_mask=[169343], unknown_class_val_mask=[169343], all_class_val_mask=[169343], test_class_mask=[169343], known_class_test_mask=[169343], unknown_class_test_mask=[169343], all_class_test_mask=[169343], unlabeled_mask=[169343])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0453f136-6431-4609-83f0-912058b814f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12, 15, 16, 19, 21, 22, 23, 24,\n",
      "        27, 28, 29, 30, 34, 37])\n"
     ]
    }
   ],
   "source": [
    "print(data.known_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ded9cc6f-6697-4496-99fe-fc3a01bb0ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  OpenGCN(in_channels = data.x.shape[1], \n",
    "                          hidden_channels = 128,\n",
    "                          out_dim =  data.classes.size(0),\n",
    "                          dropout = 0.7, \n",
    "                          num_layers = 2, \n",
    "                          known_classes = data.known_classes, \n",
    "                          unknown_classes = data.unknown_classes, \n",
    "                          device = device,\n",
    "                          log_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f41bcaa-efba-49ca-80f4-448621daccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting features for unlabeld data\n",
      "extracting features for labeld data\n",
      "{1, 34, 5, 15, 27, 28}\n",
      "{0, 2, 3, 4, 37, 6, 7, 10, 11, 12, 16, 19, 21, 22, 23, 24, 29, 30}\n",
      "estimating K ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimating K ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(cand_k)):\n\u001b[0;32m---> 42\u001b[0m     cvi_list[i],  cat_pred_i \u001b[38;5;241m=\u001b[39m \u001b[43mlabeled_val_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlv_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_feats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlt_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlt_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcand_k\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnum_val_cls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     cat_pred_list[i, :] \u001b[38;5;241m=\u001b[39m cat_pred_i\n\u001b[1;32m     44\u001b[0m     acc_list[i] \u001b[38;5;241m=\u001b[39m cluster_acc(lv_targets, cat_pred_i[\u001b[38;5;28mlen\u001b[39m(lt_targets): \u001b[38;5;28mlen\u001b[39m(lt_targets)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(lv_targets)])\n",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m, in \u001b[0;36mlabeled_val_fun\u001b[0;34m(u_feats, l_feats, l_targets, k)\u001b[0m\n\u001b[1;32m     11\u001b[0m l_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(l_targets)\n\u001b[1;32m     12\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m K_Means(k, pairwise_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_mix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_feats\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml_feats\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml_targets\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m cat_pred \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mlabels_\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \n\u001b[1;32m     15\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m cat_pred[l_num:]\n",
      "Cell \u001b[0;32mIn[17], line 156\u001b[0m, in \u001b[0;36mK_Means.fit_mix\u001b[0;34m(self, u_feats, l_feats, l_targets)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_init):\n\u001b[0;32m--> 156\u001b[0m         labels, inertia, centers, n_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_mix_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m inertia \u001b[38;5;241m<\u001b[39m best_inertia:\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_ \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mclone()\n",
      "Cell \u001b[0;32mIn[17], line 93\u001b[0m, in \u001b[0;36mK_Means.fit_mix_once\u001b[0;34m(self, u_feats, l_feats, l_targets, random_state)\u001b[0m\n\u001b[1;32m     91\u001b[0m cid2ncid \u001b[38;5;241m=\u001b[39m {cid:ncid \u001b[38;5;28;01mfor\u001b[39;00m ncid, cid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(l_classes)}  \u001b[38;5;66;03m# Create the mapping table for New cid (ncid)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(l_num):\n\u001b[0;32m---> 93\u001b[0m     labels[i] \u001b[38;5;241m=\u001b[39m cid2ncid[l_targets[i]]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m#initialize the centers, the first 'k' elements in the dataset will be our initial centers \u001b[39;00m\n\u001b[1;32m     96\u001b[0m centers\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkpp(u_feats, l_centers, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk, random_state\u001b[38;5;241m=\u001b[39mrandom_state) \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "u_num = data.y[data.unlabeled_mask].shape[0]\n",
    "\n",
    "print('extracting features for unlabeld data')\n",
    "u_targets = data.y[data.unlabeled_mask].detach().numpy()\n",
    "u_feats = model(data.x, data.edge_index)[data.unlabeled_mask, :].detach().numpy()\n",
    "\n",
    "cand_k = np.arange(max_cand_k)\n",
    "\n",
    "l_num = data.y[data.labeled_mask].shape[0]\n",
    "l_targets = data.y[data.labeled_mask].detach().numpy()\n",
    "l_feats = model(data.x, data.edge_index)[data.labeled_mask, :].detach().numpy()\n",
    "print('extracting features for labeld data')\n",
    "\n",
    "l_classes = data.known_classes.tolist()\n",
    "num_lt_cls = int(round(len(l_classes)*split_ratio))\n",
    "lt_classes = set(random.sample(l_classes, num_lt_cls)) #random sample 5 classes from all labeled classes\n",
    "lv_classes = set(l_classes) - lt_classes\n",
    "\n",
    "print(lt_classes)\n",
    "print(lv_classes)\n",
    "\n",
    "lt_feats = np.empty((0, l_feats.shape[1]))\n",
    "lt_targets = np.empty(0)\n",
    "for c in lt_classes:\n",
    "    lt_feats = np.vstack((lt_feats, l_feats[l_targets==c]))\n",
    "    lt_targets = np.append(lt_targets, l_targets[l_targets==c])\n",
    "\n",
    "lv_feats = np.empty((0, l_feats.shape[1]))\n",
    "lv_targets = np.empty(0, dtype=np.int64)\n",
    "for c in lv_classes:\n",
    "    lv_feats = np.vstack((lv_feats, l_feats[l_targets==c]))\n",
    "    lv_targets = np.append(lv_targets, l_targets[l_targets==c])\n",
    "\n",
    "\n",
    "cvi_list = np.zeros(len(cand_k))\n",
    "acc_list = np.zeros(len(cand_k))\n",
    "cat_pred_list = np.zeros([len(cand_k),u_num+l_num])\n",
    "print('estimating K ...')\n",
    "for i in range(len(cand_k)):\n",
    "    cvi_list[i],  cat_pred_i = labeled_val_fun(np.concatenate((lv_feats, u_feats)), lt_feats, lt_targets, cand_k[i]+num_val_cls)\n",
    "    cat_pred_list[i, :] = cat_pred_i\n",
    "    acc_list[i] = cluster_acc(lv_targets, cat_pred_i[len(lt_targets): len(lt_targets)+len(lv_targets)])\n",
    "    best_k = get_best_k(cvi_list[:i+1], acc_list[:i+1], cat_pred_list[:i+1], l_num) \n",
    "    print('current best K {}'.format(best_k))\n",
    "\n",
    "kmeans = KMeans(n_clusters=best_k)\n",
    "u_pred = kmeans.fit_predict(u_feats).astype(np.int32) \n",
    "acc, nmi, ari = cluster_acc(u_targets, u_pred), nmi_score(u_targets, u_pred), ari_score(u_targets, u_pred)\n",
    "print('Final K {}, acc {:.4f}, nmi {:.4f}, ari {:.4f}'.format(best_k, acc, nmi, ari))\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919a283-5183-46d2-88c4-5cc3a85f8c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737b73e-304d-4909-a798-8606dbbd5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"pown_runs_all/ogb-arxiv.csv\")\n",
    "df = pd.read_csv(path)\n",
    "df.sem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c76db8-5d4c-48ac-b564-c1b38651c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(load_folds_class_variation(\"photo\", unknown_class_ratio=0.2))\n",
    "datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303b0b5-154c-4711-b115-afb581da9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in datasets:\n",
    "    print(data.known_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a5643-e65d-4e89-aee3-6ca6e2939c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_amazon_datasets(\"photo\", train_portion=0.6, val_portion=0.2, test_portion=0.2, seed=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a1366d-eb5d-4111-ab90-b9a2ad9d393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = data.edge_index[0]\n",
    "edge_index.shape\n",
    "edge_index.max()\n",
    "data.y[edge_index].shape\n",
    "train_mask_edges = data.train_mask[edge_index]\n",
    "train_mask_edges.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26aa75-ca6a-40b5-a262-515cfa3029a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = torch.unique(data.y)\n",
    "n_classes = len(classes)\n",
    "indices = torch.randperm(n_classes)\n",
    "# Use the indices to shuffle the tensor\n",
    "classes = classes[indices]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222ea73-089c-487e-8d11-ed956aa360a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_folds(data, unknown_class_ratio):\n",
    "    classes = torch.unique(data.y)\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    # Generate a random permutation of indices\n",
    "    indices = torch.randperm(n_classes)\n",
    "    \n",
    "    # Use the indices to shuffle the tensor\n",
    "    classes = classes[indices]\n",
    "    fold_length =int(max(unknown_class_ratio * n_classes, 2))\n",
    "    \n",
    "    # Split the tensor into equal-sized folds using a loop\n",
    "    folds = [classes[i:i+fold_length] for i in range(0, n_classes, fold_length)]\n",
    "\n",
    "    if len(folds[-1])==1:\n",
    "        combined_fold = torch.cat((folds[-2], folds[-1]))\n",
    "        # Replace the last two folds with the combined fold\n",
    "        folds = folds[:-2]\n",
    "        folds.append(combined_fold)\n",
    "\n",
    "    return folds\n",
    "folds = create_class_folds(data, 0.2)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ef1bf-5382-4422-9245-45c290942082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def prepare_fold_class_variation(data, folds, train_test_index):\n",
    "\n",
    "    data = copy.deepcopy(data)\n",
    "    data.classes = torch.unique(data.y)\n",
    "    \n",
    "    known_classes = [folds[i] for i in range(len(folds)) if i < train_test_index]\n",
    "    if known_classes == []:\n",
    "        known_classes = torch.empty((0), dtype=torch.float32)\n",
    "    else:\n",
    "        known_classes = torch.cat(known_classes).sort().values\n",
    "    val_classes = torch.tensor([])#folds[val_fold_index].sort().values\n",
    "\n",
    "    \n",
    "    test_classes = [folds[i] for i in range(len(folds)) if i >= train_test_index]\n",
    "    if test_classes == []:\n",
    "        test_classes = torch.empty((0), dtype=torch.float32)\n",
    "    else:\n",
    "        test_classes = torch.cat(test_classes).sort().values\n",
    "\n",
    "    data.known_classes = known_classes\n",
    "    data.val_classes = val_classes\n",
    "    data.test_classes = test_classes\n",
    "    data.unknown_classes = torch.cat((val_classes,test_classes))\n",
    "    \n",
    "    #train mask\n",
    "    known_class_mask = torch.isin(data.y, known_classes)\n",
    "    data.known_class_mask = known_class_mask\n",
    "    data.labeled_mask = known_class_mask & data.train_mask\n",
    "\n",
    "    #val mask\n",
    "    data.val_class_mask = torch.isin(data.y, val_classes)\n",
    "    data.known_class_val_mask = known_class_mask & data.val_mask\n",
    "    data.unknown_class_val_mask = data.val_class_mask & data.val_mask\n",
    "    data.all_class_val_mask = (known_class_mask | data.val_class_mask) & data.val_mask\n",
    "\n",
    "    #test class mask\n",
    "    test_class_mask = torch.isin(data.y, test_classes)\n",
    "    data.test_class_mask = test_class_mask\n",
    "    data.known_class_test_mask = known_class_mask & data.test_mask\n",
    "    data.unknown_class_test_mask = test_class_mask & data.test_mask\n",
    "    data.all_class_test_mask = (known_class_mask | data.test_class_mask) & data.test_mask\n",
    "    \n",
    "    data.unlabeled_mask = ~data.labeled_mask\n",
    "\n",
    "    return data\n",
    "\n",
    "data = prepare_fold_class_variation(data, folds, train_test_index=1)\n",
    "print(data.known_classes, data.unknown_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d53ee-9dda-406e-85cf-336142055f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fold_data_class_variation(data, name, unknown_class_ratio):\n",
    "\n",
    "    path = Path(\"fold_indices/\"+name+\"_class_variation_class_split_\"+str(unknown_class_ratio)+\".pt\")\n",
    "    \n",
    "    if path.is_file():\n",
    "        folds = torch.load(path)\n",
    "    else:\n",
    "        folds = create_class_folds(data, unknown_class_ratio)\n",
    "        torch.save(folds, path)\n",
    "    \n",
    "    n_folds = len(folds)\n",
    "    datasets = []\n",
    "    \n",
    "    for test_split in range(n_folds+1):\n",
    "        data_new = prepare_fold_class_variation(data, folds, test_split)\n",
    "        datasets.append(data_new)\n",
    "\n",
    "    datasets = reversed(datasets)\n",
    "    return datasets\n",
    "\n",
    "datasets = create_fold_data_class_variation(data, \"photo\", unknown_class_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3462152f-5480-42d6-8388-544fa6681e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in datasets:\n",
    "    print(data.known_classes, data.unknown_classes)\n",
    "    print(torch.sum(data.all_class_test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6bcf97-4bdb-49b6-86af-fc2582f15e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = classes[n_test_classes:]\n",
    "n_val_classes = int(max(unknown_class_ratio * classes.shape[0], 2))\n",
    "val_classes = classes[:n_val_classes]\n",
    "val_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176f394-4bf5-4492-af88-d202f143f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = classes[n_val_classes:]\n",
    "train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60448291-4377-4a65-88a5-0b01130f0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds_with_resampling(data, unknown_class_ratio, n_folds):\n",
    "    folds = []\n",
    "    \n",
    "    for i in range(n_folds):\n",
    "        classes = data.y.unique()\n",
    "        n_classes = classes.max()+1\n",
    "        indices = torch.randperm(n_classes)\n",
    "        classes = classes[indices]\n",
    "        n_test_classes = max(int(unknown_class_ratio * n_classes), 2)\n",
    "        test_classes = classes[:n_test_classes]\n",
    "        classes = classes[n_test_classes:]\n",
    "        n_val_classes = max(int(unknown_class_ratio * classes.shape[0]), 2)\n",
    "        val_classes = classes[:n_val_classes]\n",
    "        train_classes = classes[n_val_classes:]\n",
    "        folds.append((train_classes, val_classes, test_classes))\n",
    "    return folds\n",
    "\n",
    "folds = create_folds_with_resampling(data, 0.5, 5)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39187f1c-5646-499c-9dcb-ec646d4ef32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fold_masks_resampling(data, fold):\n",
    "    data.classes = torch.unique(data.y)\n",
    "    data.known_classes = fold[0].sort().values\n",
    "    data.val_classes = fold[1].sort().values\n",
    "    data.test_classes = fold[2].sort().values\n",
    "    data.unknown_classes = torch.cat((data.val_classes,data.test_classes))\n",
    "\n",
    "    #train mask\n",
    "    known_class_mask = torch.isin(data.y, data.known_classes)\n",
    "    data.known_class_mask = known_class_mask\n",
    "    data.labeled_mask = known_class_mask & data.train_mask\n",
    "\n",
    "    #val mask\n",
    "    data.val_class_mask = torch.isin(data.y, data.val_classes)\n",
    "    data.known_class_val_mask = known_class_mask & data.val_mask\n",
    "    data.unknown_class_val_mask = data.val_class_mask & data.val_mask\n",
    "    data.all_class_val_mask = (known_class_mask | data.val_class_mask) & data.val_mask\n",
    "\n",
    "    #test class mask\n",
    "    test_class_mask = torch.isin(data.y, data.test_classes)\n",
    "    data.test_class_mask = test_class_mask\n",
    "    data.known_class_test_mask = known_class_mask & data.test_mask\n",
    "    data.unknown_class_test_mask = test_class_mask & data.test_mask\n",
    "    data.all_class_test_mask = (known_class_mask | data.test_class_mask) & data.test_mask\n",
    "\n",
    "    \n",
    "    data.unlabeled_mask = ~data.labeled_mask\n",
    "\n",
    "    return data\n",
    "\n",
    "prepare_fold_masks_resampling(data, folds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2cb30-6b58-40b9-b98f-322f007c2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fold_data_resampling(data, name, unknown_class_ratio, n_folds):\n",
    "\n",
    "    path = Path(\"fold_indices/\"+name+\"_class_split_\"+str(unknown_class_ratio)+\"_w_resampling\"+\".pt\")\n",
    "    \n",
    "    if path.is_file():\n",
    "        folds = torch.load(path)\n",
    "    else:\n",
    "        folds = folds = create_folds_with_resampling(data, unknown_class_ratio, n_folds)\n",
    "        torch.save(folds, path)\n",
    "    \n",
    "    n_folds = len(folds)\n",
    "    datasets = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        data_new = prepare_fold_masks_resampling(data, fold)\n",
    "        datasets.append(data_new)\n",
    "\n",
    "    return datasets\n",
    "\n",
    "create_fold_data_resampling(data, \"cora\", 0.5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933370b4-1b6f-4cdc-81fd-d260589e946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"ogb-arxiv\", unknown_class_ratio = 0.5, validation_split=True)\n",
    "print(data.known_classes)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1069abe3-903f-4f44-8fb0-3d52a045d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y[data.labeled_mask].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09d697-9d16-4020-8ce3-cf888f7c516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.x\n",
    "cosine_dist = features @ features.t()\n",
    "cosine_mat = torch.div(cosine_dist, 0.1)\n",
    "mat_max, _ = torch.max(cosine_mat, dim=1, keepdim=True)\n",
    "cosine_mat = cosine_mat - torch.diag(mat_max) #- mat_max.detach()\n",
    "sims, indices = torch.min(cosine_mat, dim=1)\n",
    "indices.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78601f62-3cd4-450c-a748-c2a2e7706c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.zeros(features.shape[0], features.shape[0], dtype=torch.bool)\n",
    "labels[:, indices] = 1\n",
    "labels[data.train_mask, data.train_mask] = torch.eq(data.y[data.train_mask] ,data.y[data.train_mask])\n",
    "labels.sum()/(2708*2708)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42413257-1153-41bb-b230-c1bbbfa63018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], page_rank=[2708], known_classes=[6], test_classes=[1], unknown_classes=[1], classes=[7], known_class_mask=[2708], test_class_mask=[2708], unknown_class_mask=[2708], known_class_test_mask=[2708], unknown_class_test_mask=[2708], labeled_mask=[2708], unlabeled_mask=[2708])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =load_dataset(\"cora\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce45f673-d6b0-47ab-8c27-d15c01ef7074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8550)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.y[data.edge_index[0]] == data.y[data.edge_index[1]]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141418b2-a5ed-4350-a18e-234e1d4553f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(data.y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00571152-f921-4bca-9812-3a568afca124",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = to_networkx(data)\n",
    "nx_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594bc53-d435-4ccf-a7fc-3064a51070be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import adjacency_matrix\n",
    "adj_mat = adjacency_matrix(nx_graph)\n",
    "adj_mat = csr_matrix(adj_mat)\n",
    "adj_mat = adj_mat.toarray()\n",
    "adj_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b4feb-887e-42d2-99ad-e7d1e03b5124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = SpectralClustering(n_clusters=6, affinity='precomputed_nearest_neighbors' , assign_labels =\"discretize\")\n",
    "sc.fit(adj_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406d110-512b-4683-849f-79de0e9d0788",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.labels_\n",
    "np.unique(sc.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d64cf4a-0733-4062-82e4-6fec841f251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_amazon_datasets(\"computers\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65364348-cf59-4098-aad5-f79c19ec25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "homophily(data.edge_index, data.y, method=\"edge_insensitive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a48a25-b11d-4239-bfe7-fdd5b713a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from handle_meta_data import load_yml\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"experiments/debug.yml\")\n",
    "\n",
    "config = load_yml(path)\n",
    "\n",
    "from collections import namedtuple\n",
    "config = namedtuple('Config', config.keys())(**config)\n",
    "\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cbd904-a64e-4aa9-8dc5-f6d3127271e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader.neighbor_loader import NeighborLoader\n",
    "import time\n",
    "data = load_dataset(\"ogb-arxiv\", unknown_class_ratio=0.4, validation_split=True)\n",
    "\n",
    "nl = NeighborLoader(data, num_neighbors=[32, 16], num_workers=5, batch_size=64)\n",
    "\n",
    "c = 0\n",
    "start = time.time()\n",
    "for b in nl:\n",
    "    c+=1\n",
    "\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37ae4d-df74-49aa-a438-2443144d2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(0,101).type(torch.float)\n",
    "print(t)\n",
    "t.quantile(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf3709-1d07-4a19-bfdc-b2a2791bdf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.init(project='ownpen_con', mode=\"online\")\n",
    "wandb.init(project='ownpen_con', mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30932106-6429-43c5-9aa7-5f9fcc018a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"cora\", unknown_class_ratio=0.2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717909bf-a9f9-4cee-92c1-6978d23f9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):\n",
    "    # Calculate element-wise squared differences\n",
    "    squared_diff = (x - y)**2\n",
    "    \n",
    "    # Sum the squared differences along the feature dimension (axis=1)\n",
    "    summed_squared_diff = squared_diff.sum(dim=1)\n",
    "    \n",
    "    # Take the square root to compute the Euclidean distance\n",
    "    distance = summed_squared_diff.sqrt()\n",
    "    \n",
    "    return distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3b9f1-82d2-4d73-ac92-fb14af0d5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "lists = [[1,2,3], [0,5,4]]\n",
    "result = not reduce(set.intersection, map(set, lists))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68515788-5b21-4931-8b8b-e018548e1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = data.edge_index\n",
    "x = data.x\n",
    "src = edge_index[0,:]\n",
    "dst = edge_index[1,:]\n",
    "eps = 0.01\n",
    "print(edge_index.shape)\n",
    "w =  euclidean_distance(x[src,:], x[dst,:])\n",
    "\n",
    "\n",
    "print(w)\n",
    "\n",
    "print(w.shape)\n",
    "w = 1/(w+eps)\n",
    "w.shape\n",
    "torch.argmax(w)\n",
    "data.edge_index[1, 624]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c9c98-40e4-4820-b6cb-c4ad9c4f4732",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478265bc-2fde-4fdb-913a-14919122c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import LabelPropagation\n",
    "\n",
    "lp = LabelPropagation(num_layers=5, alpha=0.9)\n",
    "mask = torch.zeros_like(data.train_mask)\n",
    "mask = data.train_mask\n",
    "out = lp(one_hot(data.y), data.edge_index, mask=mask, edge_weight=w, post_step=None) #.max(dim=1).values\n",
    "probs = F.softmax(out*5, dim=1)\n",
    "# Calculate the entropy for each row (dimension \"p\")\n",
    "entropies = -torch.sum(probs * torch.log(probs), dim=1)\n",
    "print(entropies.shape)\n",
    "scores, pred = probs.max(dim=1)\n",
    "probs.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd74d26-ff6a-4cb8-9146-37cc240b0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = out[5,:]\n",
    "F.softmax(p, dim=0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f342cee-77e6-4d83-b230-68b958eaa0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[2]=p[2]+0.5\n",
    "F.softmax(p, dim=0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6f030-859b-44ec-9723-3d67be884c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp(one_hot(data.y), data.edge_index, mask=data.train_mask, edge_weight=w, post_step=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b95fa4-c912-4d98-8e5a-26dd67e2689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import degree\n",
    "d = degree(data.edge_index[1,:], num_nodes=2708)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962daaa-b729-4abe-9426-1ab25e46edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices of NaN values\n",
    "nan_indices = torch.nonzero(torch.isnan(entropies)).squeeze()\n",
    "nan_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cecb6d-205f-45ba-bf7d-d8da43812fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.known_class_test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2616d9-cbf1-4df9-8a13-cf2a256860fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.full((3,), 1/3)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a915e-e50c-422e-aac6-4d9674e4905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Amazon\n",
    "data = Amazon(root='dataset/' + \"amazon_photo\", name=\"photo\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f61b38-38dd-4701-bbf5-3b8d49217763",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Amazon(root='dataset/' + \"amazon_computers\", name=\"computers\")\n",
    "x = data[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bc474-de7f-41c9-af7b-383d6e86ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = F.normalize(x) @ F.normalize(x).t()\n",
    "mat_max, _ = torch.max(cosine_sim, dim=1, keepdim=True)\n",
    "cosine_mat = cosine_sim - mat_max.detach()\n",
    "cosine_sim.min(dim=1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1b6e0-0d44-4445-b83c-6c6d8af59f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_mat.min(dim=1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165a022-1a7d-4171-913c-1cc290683e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot(data[0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0d2a6-6443-437e-8dad-7be8ea443e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cosine_sim.clone() - cosine_sim.mean(dim=1, keepdims=True)) #/ dist.std(dim=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a719a15-538b-4183-bbd7-75e396f347c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = cosine_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8606d8-d015-4084-94e9-43cf6aa0d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dist.clone() - dist.mean(dim=1, keepdims=True)) / dist.std(dim=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9848e-21d8-48ea-b0c2-33a02fa4532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_channels = 128\n",
    "num_layers = 3\n",
    "dropout = 0.7\n",
    "encoder = GCN(in_channels = -1,\n",
    "              hidden_channels = hidden_channels,\n",
    "              out_channels = None,\n",
    "              dropout = dropout,\n",
    "              num_layers = num_layers)\n",
    "\n",
    "\n",
    "\n",
    "dgi = DeepGraphInfomax(hidden_channels = hidden_channels, \n",
    "                       encoder = encoder,\n",
    "                       summary = readout,\n",
    "                       corruption = corrupt)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "og_model = OpenGraph(dgi, hidden_channels, data.classes.size(0), data.known_classes, data.unknown_classes, device, \n",
    "                     sup_loss_weight = 1, \n",
    "                     pseudo_loss_weight = 1,\n",
    "                     unsup_loss_weight = 1, \n",
    "                     ood_percentile = 1.0,\n",
    "                     proto_type=\"mean\", pseudo_label_method = \"closest\")\n",
    "og_model = og_model.to(device)\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(og_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "og_model.train()\n",
    "for epoch in tqdm(range(100)):\n",
    "    wandb.log({'epoch': epoch})\n",
    "    loss = og_model.train_one_epoch(optimizer, data)\n",
    "\n",
    "    pred = og_model.inference(data.x, data.edge_index).argmax(dim=1)\n",
    "    correct = (pred[data.known_class_val_mask] == data.y[data.known_class_val_mask]).sum()\n",
    "    val_acc = int(correct) / int(data.known_class_val_mask.sum())\n",
    "    wandb.log({'val_acc': val_acc})\n",
    "    \n",
    "og_model.final_prototypes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9851ceb-d0d2-4926-b87e-4e9e134e6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_model.eval()\n",
    "pred = og_model.inference(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.known_class_test_mask] == data.y[data.known_class_test_mask]).sum()\n",
    "acc = int(correct) / int(data.known_class_test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "pred = og_model.inference(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.unknown_class_mask] == data.y[data.unknown_class_mask]).sum()\n",
    "acc = int(correct) / int(data.unknown_class_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a9938-75f8-45a4-aa97-53c3b827542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgi = dgi.to(device)\n",
    "data = data.to(device)\n",
    "#Try RMS props?\n",
    "optimizer = torch.optim.Adam(dgi.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "dgi.train()\n",
    "for epoch in tqdm(range(500)):\n",
    "    optimizer.zero_grad()\n",
    "    pos_z, neg_z, summary = dgi.forward(data.x, data.edge_index)\n",
    "    loss = dgi.loss(pos_z, neg_z, summary)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11010fe0-6b76-4c26-997f-6c58f440224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgi.eval()\n",
    "\n",
    "pos_z, neg_z, summary = dgi.forward(data.x, data.edge_index)\n",
    "\n",
    "train_z = pos_z[data.train_mask]\n",
    "train_y = data.y[data.train_mask]\n",
    "test_z = pos_z[data.test_mask]\n",
    "test_y = data.y[data.test_mask]\n",
    "\n",
    "\n",
    "dgi.test(train_z,\n",
    "    train_y,\n",
    "    test_z,\n",
    "    test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
